{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c45825e-0783-473b-adac-45bd7953b97e",
   "metadata": {},
   "source": [
    "# RAG Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6c716f-6b4c-46e9-b6ad-10efc429fb22",
   "metadata": {},
   "source": [
    "This tutorial introduces how to create a vector database with OpenAI and MongoDB, and retrive the relevent information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a00579d-601d-4cd2-883e-8716fa956f6d",
   "metadata": {},
   "source": [
    "## Set up a Database and API Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f19853-7955-4634-b649-fb870e6cbde6",
   "metadata": {},
   "source": [
    "Create a [MongoDB](www.mongodb.com) cluster and store the connection string in a safe place, such as AWS Secrets Manager. \n",
    "- key name: `connection_string`\n",
    "- key value: <`the connection string`>, you need to type the password\n",
    "- secret name: `mongodb`\n",
    "\n",
    "\n",
    "You also need to store your oepnai api key in AWS Secrets Manager:\n",
    "- key name: `api_key`\n",
    "- key value: <`your openai api key`>\n",
    "- secret name: `openai`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741094a9-2341-428c-8890-6d25a7b5a57f",
   "metadata": {},
   "source": [
    "## Install Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0541cd55-a63a-4ea7-b109-64e638f68058",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4f0b1b-604f-4612-b949-21f988331ec8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d81b42-f298-4dc9-a774-323ce4a7abd9",
   "metadata": {},
   "source": [
    "## Secrets Manager Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193ba904-b9ee-4079-87bf-7b9e079afddb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import json\n",
    "\n",
    "def get_secret(secret_name):\n",
    "    region_name = \"us-east-1\"\n",
    "\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        raise e\n",
    "\n",
    "    secret = get_secret_value_response['SecretString']\n",
    "    \n",
    "    return json.loads(secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f82551-7cae-45a8-901f-ded99fcb1c5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import Python Libraries and Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a90eb91-dbed-45c8-954f-ec6a59066975",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "openai_api_key  = get_secret('openai')['api_key']\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "mongodb_connect = get_secret('mongodb')['connection_string']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948f4198-edb0-4004-9ccb-c4f5cc083f33",
   "metadata": {},
   "source": [
    "## Connect to the MongoDB cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c730e7-cd46-4137-819a-c0de76c2f0ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mongo_client = MongoClient(mongodb_connect)\n",
    "db = mongo_client.demo # use or create a database named demo\n",
    "tweet_collection = db.tweet_test #use or create a collection named job_collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae19a687-2bd7-4650-a4bc-c2f22b29b314",
   "metadata": {},
   "source": [
    "## Define utility funcitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bdc6aa-c9b9-4fa8-b076-e901e10ef7f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_tweet(text):\n",
    "    url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    return re.sub(url_pattern, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a14ad6e-f65b-4214-a935-acc6162116cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL= 'text-embedding-3-small'\n",
    "\n",
    "def get_embedding(text):\n",
    "\n",
    "    try:\n",
    "        embedding = client.embeddings.create(input=text, model=EMBEDDING_MODEL).data[0].embedding\n",
    "        return embedding\n",
    "    except Exception as e:\n",
    "        print(f\"Error in get_embedding: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b15875-29b8-4e60-b7b5-33cbac697182",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = 'gpt-4o'\n",
    "temperature = 0\n",
    "\n",
    "def openai_help(messages, model=model, temperature =temperature ):\n",
    "    messages = messages\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature\n",
    "\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4584482b-2cc8-47e4-8d42-d303975b4353",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vector_search(user_query):\n",
    "\n",
    "    query_embedding = get_embedding(user_query)\n",
    "    if query_embedding is None:\n",
    "        return \"Invalid query or embedding generation failed.\"\n",
    "    # Define the vector search pipeline\n",
    "    pipeline = [\n",
    "        {\n",
    "            \"$vectorSearch\": {\n",
    "                \"index\": \"vector_index\",\n",
    "                \"queryVector\": query_embedding,\n",
    "                \"path\": \"tweet.embedding\",\n",
    "                \"numCandidates\": 150,  # Number of candidate matches to consider\n",
    "                \"limit\": 10  # Return top 10 matches\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$project\": {\n",
    "                \"_id\": 0,  # Exclude the _id field\n",
    "                \"tweet.text\": 1, \n",
    "\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    results = tweet_collection.aggregate(pipeline)\n",
    "    return list(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cb5866-c09b-4779-b139-80d041a693f8",
   "metadata": {},
   "source": [
    "## tweets embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f08f57-06f8-4e9c-9388-75da5d0ea6ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "tweets = tweet_collection.find()\n",
    "\n",
    "for tweet in tqdm(tweets):\n",
    "    try:\n",
    "        tweet_embedding = get_embedding(clean_tweet(tweet['tweet']['text']))\n",
    "    #     print(tweet_embedding)\n",
    "\n",
    "        tweet_collection.update_one(\n",
    "            {'tweet.id':tweet['tweet']['id']},\n",
    "            {\"$set\":{'tweet.embedding':tweet_embedding}}\n",
    "        )\n",
    "    except:\n",
    "        print(f\"\"\"error in embedding tweet {tweet['tweet']['id']}\"\"\")\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741b8a55-60c7-4c9f-a64f-3861421e281c",
   "metadata": {},
   "source": [
    "## Create a vector index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88439dd1-13c5-4ed5-87b4-e8b644f89acf",
   "metadata": {
    "tags": []
   },
   "source": [
    "As of today, you can only create a vector index manually on MognoDB website with the folloiwng json:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"type\": \"vector\",\n",
    "      \"path\": \"tweet.embedding\",\n",
    "      \"numDimensions\": 1536,\n",
    "      \"similarity\": \"cosine\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae825bd-ffa9-45ca-bdc4-ae118a3b87c6",
   "metadata": {},
   "source": [
    "## Query the database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54c039e-9f47-4a34-8dfe-5c13f8cc2b4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_query = 'how people compare harris vs trump'\n",
    "\n",
    "for tweet in vector_search(user_query):\n",
    "    print(tweet['tweet']['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fe41db-4fa6-4269-b32c-1acd5d8e0756",
   "metadata": {},
   "source": [
    "## Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700df598-edc6-4df5-a451-af64200e60f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "delimiter = '###'\n",
    "openai_api_key  = get_secret('openai')['api_key']\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "model = 'gpt-4o'\n",
    "temperature = 0\n",
    "\n",
    "chat_history = [\n",
    "{\"role\": \"system\", \"content\": \"\"\"you are a chabot answer user questions based on the returned tweets\"\"\"}\n",
    "]\n",
    "\n",
    "def chatbot(prompt):\n",
    "\n",
    "    chat_history.append({\"role\": \"user\", \"content\": prompt})\n",
    "    \n",
    "    tweets = vector_search(prompt)\n",
    "    chat_history.append({\"role\": \"system\", \"content\": f\"here the returned tweets deliminted by {delimiter}{tweets}{delimiter}\"})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,  # Use the model you prefer\n",
    "        messages=chat_history\n",
    "    )\n",
    "\n",
    "    reply = response.choices[0].message.content\n",
    "\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": reply})\n",
    "    \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76db5ca-abb0-4c64-a85c-0fabb74f55ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in ['exit', 'quit']:\n",
    "        print(\"Chatbot: Goodbye!\")\n",
    "        break\n",
    "    reply = chatbot(user_input)\n",
    "    print(f\"Chatbot: {reply}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcb0c9e-b4d3-4355-a7fd-b10443f779e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
